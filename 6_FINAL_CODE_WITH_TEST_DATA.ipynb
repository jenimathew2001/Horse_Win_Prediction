{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This section contains the final code used for testing on the test data. I have modularized the pipeline by defining functions for all the optimized steps that contributed to improved model performance. The selected input feature set and hyperparameters used here were based on the most effective combinations observed during experimentation. Although hyperparameter tuning was conducted, the improvement over the baseline model was marginal. Therefore, the focus remained on well-engineered, race-relative features and appropriate probability calibration rather than overfitting through extensive tuning."
      ],
      "metadata": {
        "id": "PgVKz2KuzrwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "ptGIQSFkIuSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-AeoEGQRmjTW"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# IMPORT ALL THE LIBRARIES\n",
        "# -----------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.metrics import log_loss, brier_score_loss\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNCTION TO EXECUTE MODELLING TASKS"
      ],
      "metadata": {
        "id": "m2incEssIyXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# FUNCTION TO LOAD AND PREPROCESS DATA\n",
        "# -----------------------------\n",
        "\n",
        "def load_preprocess_data(mode,path):\n",
        "  data = pd.read_csv(path)\n",
        "  try:\n",
        "    #Features for Input (features were initially created and tested to check if it adds information to the model, the updated features which helped model performing better were as follows: )\n",
        "\n",
        "    # Relative speed\n",
        "    data['SpeedRel1'] = data.groupby('Race_ID')['Speed_PreviousRun'].transform(lambda x: (x - x.mean()) / x.std())\n",
        "    data['SpeedRel2'] = data.groupby('Race_ID')['Speed_2ndPreviousRun'].transform(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "    # Rank of MarketOdds within race (lower = more favored)\n",
        "    data['OddsRank1'] = data.groupby('Race_ID')['MarketOdds_PreviousRun'].rank(method='min', ascending=True)\n",
        "    data['OddsRank2'] = data.groupby('Race_ID')['MarketOdds_2ndPreviousRun'].rank(method='min', ascending=True)\n",
        "\n",
        "    # Z-score of TrainerRating within each race\n",
        "    data['TrainerRating_rel'] = data.groupby('Race_ID')['TrainerRating'].transform(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "    # Relative Damsire rating\n",
        "    data['DamsireRel'] = data.groupby('Race_ID')['DamsireRating'].transform(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "    # If test mode: data will only have input features\n",
        "    if(mode == 'train'):\n",
        "      data['Win'] = (data['Position'] == 1).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Handling Missing Values:\n",
        "    # We avoid blindly imputing global means or fixed values for missing entries, as we found most of the parameters (e.g., speed, sire rating, damsire rating) containing NAN values are horse-specific.\n",
        "    # missing values are imputed using the median value per horse, which better preserves the individual performance trends and characteristics of each horse.\n",
        "    # This needs to be updated for some parameters , as some parameters are not really horse specific\n",
        "\n",
        "    cols_with_na = data.columns[data.isna().sum() > 0].tolist()\n",
        "\n",
        "    for col in cols_with_na:\n",
        "      data[col] = data.groupby('Horse')[col].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "    # Drop incomplete races (if any missing still persist)\n",
        "    incomplete_races = data[data[cols_with_na].isna().any(axis=1)]['Race_ID'].unique()\n",
        "\n",
        "    if len(incomplete_races)>0:\n",
        "      data = data[~data['Race_ID'].isin(incomplete_races)].reset_index(drop=True)\n",
        "    incomplete_races = data[data[cols_with_na].isna().any(axis=1)]['Race_ID'].unique()\n",
        "\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "    print('OOPS! Wrong data')\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "dtkIRNDQHqoc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# FUNCTION TO EXTRACT AND TRANSFORM FEATURES\n",
        "# -----------------------------\n",
        "\n",
        "def handle_features(data,mode='train'):\n",
        "\n",
        "  # Selected Features based on testing during feature engineering\n",
        "  INP = [\n",
        "    # Historical form / fitness\n",
        "    'SpeedRel1','SpeedRel2','OddsRank1','OddsRank2','daysSinceLastRun',\n",
        "    # Ratings (aggregated skill indicators)\n",
        "    'TrainerRating_rel','JockeyRating','SireRating','DamsireRel',\n",
        "    # Demographics\n",
        "    'Age',\n",
        "    # Race configuration (distance = performance factor)\n",
        "    'distanceYards','Going'\n",
        "  ]\n",
        "\n",
        "  # Make a dictionary for going category(to save the information and to add rank)\n",
        "  going_rank = {\n",
        "    'Firm': 1,\n",
        "    'Good To Firm': 2,\n",
        "    'Good': 3,\n",
        "    'Good To Soft': 4,\n",
        "    'Soft': 5,\n",
        "    'Heavy': 6,\n",
        "    'Standard': 7\n",
        "  }\n",
        "\n",
        "  X = data[INP]\n",
        "\n",
        "  # Encode 'Going'\n",
        "  X['Going'] = X['Going'].map(going_rank)\n",
        "\n",
        "  # Scale numeric features\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  numeric_features = [col for col in INP if col != 'Going']\n",
        "  X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
        "\n",
        "  if mode == 'test':\n",
        "    return X\n",
        "\n",
        "  y = data['Win'].values\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "ACt7LP9KsbPT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# TRAIN THE MODEL\n",
        "# -----------------------------\n",
        "\n",
        "def model_fit(X,y):\n",
        "  final_model = LogisticRegression(\n",
        "    C=100,\n",
        "    penalty='l2',\n",
        "    solver='saga',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    class_weight='balanced')\n",
        "  final_model.fit(X,y)\n",
        "  return final_model"
      ],
      "metadata": {
        "id": "aP73djpu0_KI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# EVALUATION METRICS TABLE\n",
        "# -----------------------------\n",
        "\n",
        "def tabulate_result_metrics(val_data,y_val,y_pred):\n",
        "  # Confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
        "\n",
        "  sensitivity = tp / (tp + fn) if (tp + fn) else 0  # Recall\n",
        "  specificity = tn / (tn + fp) if (tn + fp) else 0\n",
        "\n",
        "  # Log Loss / Brier using softmax-normalized probs\n",
        "  true_labels = val_data['Win'].values\n",
        "  softmax_probs_pred = val_data['softmax_prob'].values\n",
        "\n",
        "  logloss = log_loss(true_labels, softmax_probs_pred)\n",
        "  brier = brier_score_loss(true_labels, softmax_probs_pred)\n",
        "  bal_acc = balanced_accuracy_score(true_labels, y_pred)\n",
        "\n",
        "  # Format as a pretty table\n",
        "  results = [\n",
        "    ['Balanced Accuracy', f'{bal_acc*100:.4f}%'],\n",
        "    ['Sensitivity (Recall)', f'{sensitivity*100:.4f}%'],\n",
        "    ['Specificity', f'{specificity*100:.4f}%'],\n",
        "    ['Log Loss (Softmax)', f'{logloss:.4f}'],\n",
        "    ['Brier Score (Softmax)', f'{brier:.4f}']\n",
        "  ]\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "pp2AZCXY_B84"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# SOFTMAX FUNCTION FOR NORMALIZED RACE PROBS\n",
        "# -----------------------------\n",
        "\n",
        "def softmax_probs(x):\n",
        "    e_x = np.exp(x - np.max(x))  # numerical stability\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "# -----------------------------\n",
        "# FUNCTION TO TEST MODEL\n",
        "# -----------------------------\n",
        "\n",
        "def test_model(model,test_data_path):\n",
        "  # Prepare test data\n",
        "  test_data = load_preprocess_data(mode = 'train',path = test_data_path)\n",
        "\n",
        "  X_test,y_test = handle_features(test_data,mode='train')\n",
        "\n",
        "  # Evaluate on test set\n",
        "  test_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Attach to validation set\n",
        "  test_data['raw_prob'] = test_probs\n",
        "\n",
        "  # Apply softmax per race\n",
        "  test_data['softmax_prob'] = test_data.groupby('Race_ID')['raw_prob'].transform(lambda x: softmax_probs(x.values))\n",
        "\n",
        "  # Predicted class from raw (not softmax)\n",
        "  y_pred = (test_data['raw_prob'] >= 0.5).astype(int)\n",
        "\n",
        "  # Print results\n",
        "  results = tabulate_result_metrics(test_data,y_test,y_pred)\n",
        "  print(tabulate(results, headers=['Metric', 'Value'], tablefmt='grid'))\n",
        "\n",
        "  # Ensure column is named correctly\n",
        "  test_data['Predicted_Probability'] = test_data['softmax_prob']\n",
        "\n",
        "  # Select only required columns\n",
        "  submission_df = test_data[['Race_ID', 'Position', 'Predicted_Probability']].copy()\n",
        "\n",
        "  # Save to CSV\n",
        "  submission_df.to_csv(\"test_predictions.csv\", index=False)\n",
        "\n",
        "  print(\"Saved to test_predictions.csv\")"
      ],
      "metadata": {
        "id": "SSTzpic212XO"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN EXECUTION"
      ],
      "metadata": {
        "id": "Rmnd8FfwI3Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# MAIN EXECUTION\n",
        "# -----------------------------\n",
        "\n",
        "data = load_preprocess_data(mode='train',path='/content/trainData.csv')\n",
        "X,y = handle_features(data,mode='train')\n",
        "model = model_fit(X,y)\n",
        "test_model(model,'/content/testData.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUxSK87IMVMK",
        "outputId": "568d1b67-3f61-4efe-f176-629b0fac07ca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-d077e3b8d2f4>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Going'] = X['Going'].map(going_rank)\n",
            "<ipython-input-67-d077e3b8d2f4>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
            "<ipython-input-67-d077e3b8d2f4>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Going'] = X['Going'].map(going_rank)\n",
            "<ipython-input-67-d077e3b8d2f4>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[numeric_features] = scaler.fit_transform(X[numeric_features])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+----------+\n",
            "| Metric                | Value    |\n",
            "+=======================+==========+\n",
            "| Balanced Accuracy     | 62.8455% |\n",
            "+-----------------------+----------+\n",
            "| Sensitivity (Recall)  | 66.5543% |\n",
            "+-----------------------+----------+\n",
            "| Specificity           | 59.1366% |\n",
            "+-----------------------+----------+\n",
            "| Log Loss (Softmax)    | 0.3310   |\n",
            "+-----------------------+----------+\n",
            "| Brier Score (Softmax) | 0.0943   |\n",
            "+-----------------------+----------+\n",
            "Saved to test_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}